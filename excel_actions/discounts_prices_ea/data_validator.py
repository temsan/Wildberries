"""
Data validator for discounts_prices data.

–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É API –∏ Google —Ç–∞–±–ª–∏—Ü–µ–π.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ API —Å –¥–∞–Ω–Ω—ã–º–∏, –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–º–∏ –≤ Google —Ç–∞–±–ª–∏—Ü—É.
"""

from __future__ import annotations

from typing import Any, Dict, Iterable, List, Tuple
from pathlib import Path
import importlib.util
import logging
import sys
import time

logger = logging.getLogger(__name__)

# Import Google credentials path
BASE_DIR = Path(__file__).resolve().parents[2]
api_keys_path = BASE_DIR / 'api_keys.py'
spec = importlib.util.spec_from_file_location("api_keys", str(api_keys_path))
api_keys_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(api_keys_module)
GOOGLE_CREDENTIALS_FILE = api_keys_module.GOOGLE_CREDENTIALS_FILE
GOOGLE_SHEET_ID_UNIT_ECONOMICS = api_keys_module.GOOGLE_SHEET_ID_UNIT_ECONOMICS
GOOGLE_SHEET_NAME_DISCOUNTS_PRICES = getattr(api_keys_module, "GOOGLE_SHEET_NAME_DISCOUNTS_PRICES", "—é–Ω–∏—Ç–∫–∞")

# Import header mapping utilities
header_mapping_path = Path(__file__).resolve().parents[1] / 'utils' / 'header_mapping.py'
spec_header = importlib.util.spec_from_file_location("header_mapping", str(header_mapping_path))
header_mapping_module = importlib.util.module_from_spec(spec_header)
sys.modules[spec_header.name] = header_mapping_module
spec_header.loader.exec_module(header_mapping_module)
load_header_map = header_mapping_module.load_header_map
HeaderMappingError = header_mapping_module.HeaderMappingError

# Header configuration (shared constants)
config_path = Path(__file__).resolve().with_name('header_config.py')
spec_config = importlib.util.spec_from_file_location("header_config", str(config_path))
header_config = importlib.util.module_from_spec(spec_config)
spec_config.loader.exec_module(header_config)

HEADER_ROW_INDEX = header_config.HEADER_ROW_INDEX
DISCOUNTS_PRICES_HEADER_ALIASES = header_config.DISCOUNTS_PRICES_HEADER_ALIASES
DATA_COLUMN_KEYS = header_config.DATA_COLUMN_KEYS


def _get_service(credentials_info=None):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–µ—Ä–≤–∏—Å Google Sheets API."""
    from google.oauth2.service_account import Credentials
    from googleapiclient.discovery import build

    scopes = ['https://www.googleapis.com/auth/spreadsheets']

    if credentials_info:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ credentials
        credentials = Credentials.from_service_account_info(credentials_info, scopes=scopes)
    else:
        # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É –º–µ—Ç–æ–¥—É —Å —Ñ–∞–π–ª–æ–º
        credentials = Credentials.from_service_account_file(GOOGLE_CREDENTIALS_FILE, scopes=scopes)

    return build('sheets', 'v4', credentials=credentials)


def _col_index_to_label(index_1based: int) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–±—Ü–∞ (1-based) –≤ –±—É–∫–≤–µ–Ω–Ω–æ–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ (A, B, C, ...)."""
    label = ""
    n = index_1based
    while n > 0:
        n, rem = divmod(n - 1, 26)
        label = chr(65 + rem) + label
    return label


def _col_letters_to_index(col_letters: str) -> int:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±—É–∫–≤–µ–Ω–Ω–æ–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ (A, B, C, ...) –≤ –∏–Ω–¥–µ–∫—Å (1-based)."""
    idx = 0
    for ch in col_letters:
        idx = idx * 26 + (ord(ch.upper()) - 64)
    return idx


def _batch_read_sheet_data(
    service,
    spreadsheet_id: str,
    sheet_name: str,
    header_map,
    start_row: int,
    column_keys: Iterable[str],
) -> Tuple[Dict[str, int], Dict[str, Dict[str, Any]]]:
    """
    –ß–∏—Ç–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets –∑–∞ –æ–¥–∏–Ω batch-–∑–∞–ø—Ä–æ—Å.
    
    Args:
        service: Google Sheets API service
        spreadsheet_id: ID —Ç–∞–±–ª–∏—Ü—ã
        sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞
        article_col: –°—Ç–æ–ª–±–µ—Ü —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
        start_row: –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        columns_order: –ü–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —á—Ç–µ–Ω–∏—è
        
    Returns:
        Tuple[Dict[str, int], Dict[str, Dict[str, Any]]]: 
        (article_row_map, sheet_data)
    """
    
    # –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã
    nm_header = header_map.get("nmID")
    print(f"üìã –ß–∏—Ç–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ —Å—Ç–æ–ª–±—Ü–∞ {nm_header.letter}...")
    article_range = header_map.build_column_range("nmID", start_row)
    article_res = service.spreadsheets().values().get(
        spreadsheetId=spreadsheet_id, 
        range=article_range
    ).execute()
    article_values = article_res.get('values', [])
    
    # –°—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É –∞—Ä—Ç–∏–∫—É–ª–æ–≤
    article_row_map = {}
    for offset, row_vals in enumerate(article_values, start=0):
        cell = row_vals[0].strip() if row_vals else ""
        if not cell:
            continue
        row_num = start_row + offset
        article = str(cell)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        if not article.isdigit():
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Å—Ç—Ä–æ–∫–µ {row_num}: '{article}'")
            continue
            
        if article not in article_row_map:
            article_row_map[article] = row_num
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(article_row_map)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü–µ")
    
    if not article_row_map:
        return article_row_map, {}
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª—é—á—É –æ—Ç–¥–µ–ª—å–Ω–æ (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –ø—Ä–æ–ø—É—Å–∫–∞–º –∏ —Ä–∞–∑—Ä—ã–≤–∞–º –∫–æ–ª–æ–Ω–æ–∫)
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –¥–ª—è batchGet
    ranges = [header_map.build_column_range(key, start_row) for key in column_keys]
    if ranges:
        print(f"üìã –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ {len(ranges)} –∫–æ–ª–æ–Ω–∫–∞–º...")
        batch_res = service.spreadsheets().values().batchGet(
            spreadsheetId=spreadsheet_id,
            ranges=ranges,
            valueRenderOption='UNFORMATTED_VALUE',
            dateTimeRenderOption='SERIAL_NUMBER',
        ).execute()
        value_ranges = batch_res.get('valueRanges', [])
    else:
        value_ranges = []

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    sheet_data: Dict[str, Dict[str, Any]] = {}

    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤
    def _parse_numeric(value: Any) -> float:
        try:
            if isinstance(value, str) and ',' in value:
                value = value.replace(',', '.')
            return float(value) if value not in (None, "") else 0.0
        except (ValueError, TypeError):
            return 0.0

    def _parse_bool(value: Any) -> bool:
        return str(value).lower() in ['true', '1', '–¥–∞', 'yes']

    # –†–∞–∑–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç—ã –ø–æ –ø–æ—Ä—è–¥–∫—É –∫–ª—é—á–µ–π
    for key_idx, col_name in enumerate(column_keys):
        if key_idx >= len(value_ranges):
            continue
        vr = value_ranges[key_idx]
        col_values = vr.get('values', [])

        for offset, row_vals in enumerate(col_values, start=0):
            row_num = start_row + offset
            # –ù–∞—Ö–æ–¥–∏–º –∞—Ä—Ç–∏–∫—É–ª –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
            # –ë—ã—Å—Ç—Ä–µ–µ –¥–µ—Ä–∂–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é –∫–∞—Ä—Ç—É: row -> article
            # –ü–æ—Å—Ç—Ä–æ–∏–º –Ω–∞ –ª–µ—Ç—É –æ–¥–∏–Ω —Ä–∞–∑
            # (–ø–µ—Ä–µ–Ω–æ—Å–∏–º –∏–∑ article_row_map)
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º sheet_row
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ
            article = None
            for art, art_row in article_row_map.items():
                if art_row == row_num:
                    article = art
                    break
            if not article:
                continue

            row_value = row_vals[0] if row_vals else ""
            if article not in sheet_data:
                sheet_data[article] = {}

            if col_name in ["prices", "discount", "discountedPrices", "discountOnSite", "priceafterSPP", "competitivePrice"]:
                sheet_data[article][col_name] = _parse_numeric(row_value)
            elif col_name in ["isCompetitivePrice", "hasPromotions"]:
                sheet_data[article][col_name] = _parse_bool(row_value)
            else:
                sheet_data[article][col_name] = row_value

    print(f"üìä –ü—Ä–æ—á–∏—Ç–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(sheet_data)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
    return article_row_map, sheet_data


def _legacy_read_sheet_data(
    service,
    spreadsheet_id: str,
    sheet_name: str,
    article_col: str,
    start_row: int,
    column_keys: List[str]
) -> Tuple[Dict[str, int], Dict[str, Dict[str, Any]]]:
    """
    –°—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–± —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (–ø–æ—Å—Ç—Ä–æ—á–Ω–æ —Å rate limiting).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏–ª–∏ –∫–æ–≥–¥–∞ batch-—á—Ç–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.
    """
    
    # –°—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
    article_row_map = {}
    try:
        rng = f"{sheet_name}!{article_col}{start_row}:{article_col}"
        res = service.spreadsheets().values().get(spreadsheetId=spreadsheet_id, range=rng).execute()
        values = res.get('values', [])
        
        for offset, row_vals in enumerate(values, start=0):
            cell = row_vals[0].strip() if row_vals else ""
            if not cell:
                continue
            row_num = start_row + offset
            article = str(cell)
            if article not in article_row_map:
                article_row_map[article] = row_num
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return {}, {}
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ —Å rate limiting
    sheet_data = {}
    total_articles = len(article_row_map)
    processed_count = 0
    
    print(f"üìä –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {total_articles} –∞—Ä—Ç–∏–∫—É–ª–æ–≤ —Å rate limiting...")
    print(f"   ‚Ä¢ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: 1.2 —Å–µ–∫")
    print(f"   ‚Ä¢ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~{total_articles * 1.2 / 60:.1f} –º–∏–Ω")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    article_col_index = _col_letters_to_index(article_col)
    start_col_index = article_col_index + 1
    start_col_letter = _col_index_to_label(start_col_index)
    
    for article, row_num in article_row_map.items():
        try:
            # Rate limiting: –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if processed_count > 0:
                time.sleep(1.2)
            
            # –ß–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞–Ω–Ω—ã–º–∏
            end_col_index = start_col_index + len(column_keys) - 1
            end_col_letter = _col_index_to_label(end_col_index)
            data_range = f"{sheet_name}!{start_col_letter}{row_num}:{end_col_letter}{row_num}"
            
            res = service.spreadsheets().values().get(spreadsheetId=spreadsheet_id, range=data_range).execute()
            values = res.get('values', [])
            
            if values and values[0]:
                row_data = values[0]
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
                sheet_row = {}
                for i, col_name in enumerate(column_keys):
                    if i < len(row_data):
                        value = row_data[i]
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∫ –Ω—É–∂–Ω—ã–º —Ç–∏–ø–∞–º
                        if col_name in ["prices", "discount", "discountedPrices", "discountOnSite", "priceafterSPP", "competitivePrice"]:
                            try:
                                sheet_row[col_name] = float(value) if value else 0.0
                            except (ValueError, TypeError):
                                sheet_row[col_name] = 0.0
                        elif col_name in ["isCompetitivePrice", "hasPromotions"]:
                            sheet_row[col_name] = str(value).lower() in ['true', '1', '–¥–∞', 'yes']
                        else:
                            sheet_row[col_name] = value
                    else:
                        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        if col_name in ["prices", "discount", "discountedPrices", "discountOnSite", "priceafterSPP", "competitivePrice"]:
                            sheet_row[col_name] = 0.0
                        elif col_name in ["isCompetitivePrice", "hasPromotions"]:
                            sheet_row[col_name] = False
                        else:
                            sheet_row[col_name] = ""
                
                sheet_data[article] = sheet_row
            
            processed_count += 1
            if processed_count % 10 == 0:  # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 –∞—Ä—Ç–∏–∫—É–ª–æ–≤
                print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}/{total_articles} ({processed_count/total_articles*100:.1f}%)")
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª–∞ {article}: {e}")
            processed_count += 1
            continue
    
    return article_row_map, sheet_data


def check_data_completeness(
    sheet_data: Dict[str, Dict[str, Any]], 
    column_keys: List[str]
) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ Google Sheets.
    
    Args:
        sheet_data: –î–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
        columns_order: –ü–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã
    """
    
    print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ {len(sheet_data)} –∞—Ä—Ç–∏–∫—É–ª–∞—Ö...")
    
    total_articles = len(sheet_data)
    empty_articles = 0
    incomplete_articles = 0
    complete_articles = 0
    
    empty_fields = {col: 0 for col in column_keys}
    incomplete_details = []
    
    for article, row_data in sheet_data.items():
        has_empty_fields = False
        article_empty_fields = []
        
        for col_name in column_keys:
            value = row_data.get(col_name, 0)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ "–ø—É—Å—Ç—ã–º"
            is_empty = False
            if col_name in ["prices", "discount", "discountedPrices", "discountOnSite", "priceafterSPP", "competitivePrice"]:
                is_empty = value == 0.0 or value is None
            elif col_name in ["isCompetitivePrice", "hasPromotions"]:
                is_empty = value is False  # False —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—É—Å—Ç—ã–º –¥–ª—è –±—É–ª–µ–≤—ã—Ö –ø–æ–ª–µ–π
            else:
                is_empty = not value or str(value).strip() == ""
            
            if is_empty:
                empty_fields[col_name] += 1
                article_empty_fields.append(col_name)
                has_empty_fields = True
        
        if not article_empty_fields:
            complete_articles += 1
        elif len(article_empty_fields) == len(column_keys):
            empty_articles += 1
        else:
            incomplete_articles += 1
            incomplete_details.append({
                "article": article,
                "empty_fields": article_empty_fields
            })
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—è–º
    field_stats = {
        col_name: {
            "empty_count": empty_fields[col_name],
            "empty_percentage": (empty_fields[col_name] / total_articles * 100) if total_articles > 0 else 0,
        }
        for col_name in column_keys
    }
    
    result = {
        "total_articles": total_articles,
        "complete_articles": complete_articles,
        "incomplete_articles": incomplete_articles,
        "empty_articles": empty_articles,
        "field_stats": field_stats,
        "incomplete_details": incomplete_details[:10],  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        "completeness_percentage": (complete_articles / total_articles * 100) if total_articles > 0 else 0
    }
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤: {total_articles}")
    print(f"   ‚Ä¢ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö: {complete_articles} ({result['completeness_percentage']:.1f}%)")
    print(f"   ‚Ä¢ –ß–∞—Å—Ç–∏—á–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö: {incomplete_articles}")
    print(f"   ‚Ä¢ –ü—É—Å—Ç—ã—Ö: {empty_articles}")
    
    print(f"\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—è–º:")
    for col_name, stats in field_stats.items():
        print(f"   ‚Ä¢ {col_name}: {stats['empty_count']} –ø—É—Å—Ç—ã—Ö ({stats['empty_percentage']:.1f}%)")
    
    
    return result


def validate_data_integrity(
    processed_data: List[Dict[str, Any]],
    # ========== –ù–ê–°–¢–†–û–ô–ö–ò - –ò–ó–ú–ï–ù–ò–¢–ï –ü–†–ò –ù–ï–û–ë–•–û–î–ò–ú–û–°–¢–ò ==========
    sheet_name: str = GOOGLE_SHEET_NAME_DISCOUNTS_PRICES,  # –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    article_search_range: str = "A:A",  # –î–∏–∞–ø–∞–∑–æ–Ω –ø–æ–∏—Å–∫–∞ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
    start_row: int = 1,  # –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    use_batch_reading: bool = True,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å batch-—á—Ç–µ–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
    # ============================================
    spreadsheet_id: str = GOOGLE_SHEET_ID_UNIT_ECONOMICS,
    credentials_info: Dict[str, Any] = None,  # Google credentials (–∏–∑ api_keys.py)
) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É API –∏ Google —Ç–∞–±–ª–∏—Ü–µ–π.
    
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ API —Å –¥–∞–Ω–Ω—ã–º–∏, –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–º–∏ –≤ Google —Ç–∞–±–ª–∏—Ü—É.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—Å–µ—Ö –ø–æ–ª–µ–π: prices, discount, discountedPrices, etc.
    
    Args:
        processed_data: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ data_processor
        sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        article_search_range: –î–∏–∞–ø–∞–∑–æ–Ω –ø–æ–∏—Å–∫–∞ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        start_row: –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        use_batch_reading: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å batch-—á—Ç–µ–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        spreadsheet_id: ID Google —Ç–∞–±–ª–∏—Ü—ã
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏:
        {
            "total_checked": int,           # –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
            "perfect_matches": int,         # –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö
            "mismatches": int,              # –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            "not_found_in_sheet": int,      # –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü–µ
            "mismatch_details": List[Dict], # –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            "validation_passed": bool       # –ü—Ä–æ—à–ª–∞ –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
        }
    """
    
    print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ª–∏—Å—Ç–µ '{sheet_name}'...")
    print(f"üîß –†–µ–∂–∏–º: {'Batch-—á—Ç–µ–Ω–∏–µ' if use_batch_reading else '–ü–æ—Å—Ç—Ä–æ—á–Ω–æ–µ —á—Ç–µ–Ω–∏–µ'}")
    
    service = _get_service(credentials_info)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–∞—Ä—Ç—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    header_map = load_header_map(
        service=service,
        spreadsheet_id=spreadsheet_id,
        sheet_name=sheet_name,
        expected_headers=DISCOUNTS_PRICES_HEADER_ALIASES,
        header_row=HEADER_ROW_INDEX,
    )
    # –¢—Ä–µ–±—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ –∞—Ä—Ç–∏–∫—É–ª–∞, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ
    try:
        header_map.get("nmID")
    except HeaderMappingError:
        raise HeaderMappingError("Missing required header: nmID")

    nm_header = header_map.get("nmID")
    print(f"üìã –°—Ç–æ–ª–±–µ—Ü —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏: {nm_header.letter}")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏ –∫–æ–ª–æ–Ω–æ–∫ –∏ –ª–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ/–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ
    resolved_pairs = [(k, header_map.get_optional(k)) for k in DATA_COLUMN_KEYS]
    column_keys = [k for k, info in resolved_pairs if info is not None]
    skipped_keys = [k for k, info in resolved_pairs if info is None]
    if skipped_keys:
        logger.info("–ü—Ä–æ–ø—É—â–µ–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏: %s", ", ".join(skipped_keys))
    if column_keys:
        logger.info("–ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: %s", ", ".join(column_keys))
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
    try:
        if use_batch_reading:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º batch-—á—Ç–µ–Ω–∏–µ (–±—ã—Å—Ç—Ä–æ –∏ –Ω–∞–¥–µ–∂–Ω–æ)
            article_row_map, sheet_data = _batch_read_sheet_data(
                service=service,
                spreadsheet_id=spreadsheet_id,
                sheet_name=sheet_name,
                header_map=header_map,
                start_row=start_row,
        column_keys=column_keys,
            )
        else:
            # –°—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–± (–º–µ–¥–ª–µ–Ω–Ω—ã–π, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
            article_row_map, sheet_data = _legacy_read_sheet_data(
                service,
                spreadsheet_id,
                sheet_name,
                header_map.get("nmID").letter,
                start_row,
                column_keys,
            )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return {"error": str(e)}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ Google Sheets...")
    completeness_result = check_data_completeness(sheet_data, column_keys)
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    total_checked = 0
    perfect_matches = 0
    mismatches = 0
    not_found_in_sheet = 0
    mismatch_details = []
    
    for item in processed_data:
        nm_id = str(item.get('nmID', ''))
        if not nm_id:
            continue
            
        total_checked += 1
        
        if nm_id not in sheet_data:
            not_found_in_sheet += 1
            continue
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –ø–æ–ª–µ
        sheet_row = sheet_data[nm_id]
        item_mismatches = []
        
        for col_name in column_keys:
            api_value = item.get(col_name, 0)
            sheet_value = sheet_row.get(col_name, 0)

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤ (–ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ –ª–∏—Å—Ç–µ –∫–∞–∫ –¥–æ–ª—è)
            if col_name in ["prices", "discount", "discountedPrices", "discountOnSite", "priceafterSPP", "competitivePrice"]:
                api_num = float(api_value)
                sheet_num = float(sheet_value)
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –ø–æ–ª–µ–π: –≤ –ª–∏—Å—Ç–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –¥–æ–ª—è (0.3), –≤ API ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç—ã (30)
                if col_name in ["discount", "discountOnSite"]:
                    sheet_num = sheet_num * 100
                if abs(api_num - sheet_num) > 0.01:
                    item_mismatches.append({
                        "field": col_name,
                        "api_value": api_value,
                        "sheet_value": sheet_value
                    })
            else:
                # –î–ª—è –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                if bool(api_value) != bool(sheet_value):
                    item_mismatches.append({
                        "field": col_name,
                        "api_value": api_value,
                        "sheet_value": sheet_value
                    })
        
        if item_mismatches:
            mismatches += 1
            mismatch_details.append({
                "nm_id": nm_id,
                "mismatches": item_mismatches
            })
        else:
            perfect_matches += 1
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø—Ä–æ—à–ª–∞ –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –Ω–µ—Ç –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü–µ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)
    validation_passed = mismatches == 0
    
    result = {
        "total_checked": total_checked,
        "perfect_matches": perfect_matches,
        "mismatches": mismatches,
        "not_found_in_sheet": not_found_in_sheet,
        "mismatch_details": mismatch_details,
        "validation_passed": validation_passed,
        "completeness_result": completeness_result
    }
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {total_checked}")
    print(f"   ‚Ä¢ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö: {perfect_matches}")
    print(f"   ‚Ä¢ –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {mismatches}")
    print(f"   ‚Ä¢ –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü–µ: {not_found_in_sheet}")
    print(f"   ‚Ä¢ –í–∞–ª–∏–¥–∞—Ü–∏—è {'‚úÖ –ü–†–û–®–õ–ê' if validation_passed else '‚ùå –ù–ï –ü–†–û–®–õ–ê'}")
    
    if mismatch_details:
        print(f"\nüîç –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 5):")
        for i, detail in enumerate(mismatch_details[:5]):
            print(f"   ‚Ä¢ –ê—Ä—Ç–∏–∫—É–ª {detail['nm_id']}:")
            for mismatch in detail['mismatches']:
                print(f"     - {mismatch['field']}: API={mismatch['api_value']}, Sheet={mismatch['sheet_value']}")
    
    return result


def print_validation_report(result: Dict[str, Any]) -> None:
    """
    –í—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        result: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑ validate_data_integrity
    """
    print("\n" + "="*80)
    print("üìä –û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò –î–ê–ù–ù–´–•")
    print("="*80)
    
    print(f"üì¶ –í—Å–µ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {result['total_checked']}")
    print(f"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö: {result['perfect_matches']}")
    print(f"‚ùå –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {result['mismatches']}")
    print(f"üîç –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü–µ: {result['not_found_in_sheet']}")
    
    
    if result['mismatches'] > 0:
        print(f"\nüîç –î–ï–¢–ê–õ–ò –ù–ï–°–û–í–ü–ê–î–ï–ù–ò–ô:")
        for detail in result['mismatch_details']:
            print(f"\n   –ê—Ä—Ç–∏–∫—É–ª {detail['nm_id']}:")
            for mismatch in detail['mismatches']:
                print(f"     ‚Ä¢ {mismatch['field']}: API={mismatch['api_value']}, Sheet={mismatch['sheet_value']}")
    
    print(f"\nüéØ –ò–¢–û–ì: {'‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ü–†–û–®–õ–ê' if result['validation_passed'] else '‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø –ù–ï –ü–†–û–®–õ–ê'}")
    print("="*80)
